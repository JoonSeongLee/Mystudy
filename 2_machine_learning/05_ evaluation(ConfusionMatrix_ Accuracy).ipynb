{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류 성능 평가\n",
    "\n",
    "## Scikit-Learn 에서 지원하는 분류 성능 평가 명령"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.metrics` 서브 패키지\n",
    " * `confusion_matrix()`\n",
    " * `classfication_report()`\n",
    " * `accuracy_score(y_true, y_pred)`\n",
    " * `precision_score(y_true, y_pred)`\n",
    " * `recall_score(y_true, y_pred)`\n",
    " * `fbeta_score(y_true, y_pred, beta)`\n",
    " * `f1_score(y_true, y_pred)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류 결과표 Confusion Matrix\n",
    "\n",
    "| | 예측 클래스 0 | 예측 클래스 1 | 예측 클래스 2 | \n",
    "|-|-|-|-|\n",
    "| 원 클래스 0 | <small>원 클래스가 0, 예측 클래스가 0인 표본의 수</small> | <small>원 클래스가 0, 예측 클래스가 1인 표본의 수</small> | <small>원 클래스가 0, 예측 클래스가 2인 표본의 수</small> |\n",
    "| 원 클래스 1 | <small>원 클래스가 1, 예측 클래스가 0인 표본의 수</small> | <small>원 클래스가 1, 예측 클래스가 1인 표본의 수</small> | <small>원 클래스가 1, 예측 클래스가 2인 표본의 수</small> |\n",
    "| 원 클래스 2 | <small>원 클래스가 2, 예측 클래스가 0인 표본의 수</small> | <small>원 클래스가 2, 예측 클래스가 1인 표본의 수</small> | <small>원 클래스가 2, 예측 클래스가 2인 표본의 수</small> |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [7, 0, 7, 7, 0, 6]\n",
    "y_pred = [0, 0, 7, 7, 0, 7]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이진 분류 결과표 Binary Confusion Matrix\n",
    "\n",
    "| | Positive라고 예측  | Negative라고 예측 | \n",
    "|-|-|-|\n",
    "| 실제 Positive | TP   |  FN |             \n",
    "| 실제 Negative | FP   |  TN |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy 정확도\n",
    "* 전체 샘플 중 맞게 예측한 샘플 수의 비율\n",
    "* 모형 트레이닝 즉 최적화에서 목적함수로 사용  \n",
    " \n",
    " $$\\text{accuracy} = \\dfrac{TP + TN}{TP + TN + FP + FN}$$\n",
    " \n",
    "### Precision 정밀도\n",
    "* 클래스에 속한다고 출력한 샘플 중 실제로 클래스에 속하는 샘플 수의 비율\n",
    "* FDS의 경우, 사기 거래라고 판단한 거래 중 실제 사기 거래의 비율. 유죄율\n",
    " \n",
    "$$\\text{precision} = \\dfrac{TP}{TP + FP}$$\n",
    "\n",
    "### Recall 재현율\n",
    "* 실제 클래스에 속한 샘플 중에 클래스에 속한다고 출력한 샘플의 수\n",
    "* FDS의 경우, 실제 사기 거래 중에서 실제 사기 거래라고 예측한 거래의 비율. 검거율\n",
    "* TPR(true positive rate)\n",
    "* sensitivity(민감도)\n",
    " \n",
    "$$\\text{recall} = \\dfrac{TP}{TP + FN}$$\n",
    "\n",
    "### Fall-Out 위양성율\n",
    "* 실제 클래스에 속하지 않는 샘플 중에 클래스에 속한다고 출력한 샘플의 수\n",
    "* FDS의 경우, 실제 정상 거래 중에서 FDS가 사기 거래라고 예측한 거래의 비율, 원죄(寃罪)율\n",
    "* FPR(alse positive rate)\n",
    "* specificity(특이도) = 1 - fall-out\n",
    "\n",
    "$$\\text{fallout} = \\dfrac{FP}{FP + TN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F (beta) score\n",
    "* 정밀도(Precision)과 재현율(Recall)의 가중 조화 평균\n",
    " \n",
    "$$\n",
    "F_\\beta = (1 + \\beta^2) \\, ({\\text{precision} \\times \\text{recall}}) \\, / \\, ({\\beta^2 \\, \\text{precision} + \\text{recall}})\n",
    "$$\n",
    "\n",
    "\n",
    "* F1 score\n",
    " * beta = 1 \n",
    "\n",
    "$$\n",
    "F_1 = 2 \\cdot \\text{precision} \\cdot \\text{recall} \\, / \\, (\\text{precision} + \\text{recall})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.50      1.00      0.67         1\n",
      "    class 1       0.00      0.00      0.00         1\n",
      "    class 2       1.00      0.67      0.80         3\n",
      "\n",
      "avg / total       0.70      0.60      0.61         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "y_true = [0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 2, 1]\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC 커브ROC(Receiver Operator Characteristic)\n",
    "\n",
    "클래스 판별 기준값의 변화에 따른 Fall-out과 Recall의 변화를 시각화한 것이다.\n",
    "\n",
    "모든 이진 분류 모형은 판별 평면으로부터의 거리에 해당하는 판별 함수(discriminant function)를 가지며 판별 함수 값이 음수이면 0인 클래스, 양수이면 1인 클래스에 해당한다고 판별한다. 즉 0 이 클래스 판별 기준값이 된다. ROC 커브는 이 클래스 판별 기준값이 달라진다면 판별 결과가 어떻게 달라지는지는 표현한 것이다.\n",
    "\n",
    "Scikit-Learn 의 Classification 클래스는 판별 함수 값을 계산하는 `decision_function` 메서드를 제공한다. ROC 커브는 이 판별 함수 값을 이용하여 다음과 같이 작성한다.\n",
    "\n",
    "1. 모든 표본 데이터에 대해 판별 함수 값을 계산한다.\n",
    "2. 계산된 판별 함수 값을 정렬한다.\n",
    "3. 만약 0이 아닌 가장 작은 판별 함수값을 클래스 구분 기준값으로 하면 모든 표본은 클래스 1(Positive)이 된다. \n",
    "   이 때의 Fall-out과 Recall을 계산하면 Recall과 Fall-out이 모두 1이된다.\n",
    "4. 두번째로 작은 판별 함수값을 클래스 구분 기준값으로 하면 판별 함수 값이 가장 작은 표본 1개를 제외하고 나머지 표본은 클래스 1(Positive)이 된다. 마찬가지로 이 때의 Fall-out과 Recall을 계산하여 기록한다.\n",
    "5. 가장 큰 판별 함수값이 클래스 구분 기준값이 될 때까지 이를 반복한다. 이 때는 모든 표본이 클래스 0(Negative)으로 판별되며 Recall과 Fall-out이 모두 0이된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
