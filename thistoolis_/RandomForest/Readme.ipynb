{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# RandomForestClassifier()\n",
    "\n",
    "class sklearn.ensemble.`RandomForestClassifier`(n_estimators=10, criterion=’gini’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters:\t\n",
    "\n",
    "n_estimators : integer, optional (default=10)\n",
    "\n",
    "    결정트리의 갯수\n",
    "\n",
    "\n",
    "criterion : string, optional (default=”gini”)\n",
    "\n",
    "    The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.\n",
    "    \n",
    "\n",
    "max_features : int, float, string or None, optional (default=”auto”)\n",
    "\n",
    "    고려해야 할 feature의 수 :\n",
    "    \n",
    "    int   :  then consider max_features features at each split.\n",
    "    float :  백분율\n",
    "    auto  :  sqrt(n_features)\n",
    "    sqrt  :  sqrt(n_features) \n",
    "    log2  :  log2(n_features)\n",
    "    None  :   n_features.\n",
    "    \n",
    "\n",
    "max_depth : integer or None, optional (default=None)\n",
    "\n",
    "    나무의 최대 깊이\n",
    "    (모든 잎이 순수하거나 모든 잎이 min_samples_split 샘플보다 작아 질 때까지 노드가 확장됩니다.)\n",
    "    \n",
    "\n",
    "min_samples_split : int, float, optional (default=2)\n",
    "\n",
    "    분할하는데 필요한 최소 샘플 수\n",
    "    \n",
    "\n",
    "min_samples_leaf : int, float, optional (default=1)\n",
    "\n",
    "    리프에 있어야 하는 최소 샘플 수\n",
    "\n",
    "\n",
    "min_weight_fraction_leaf : float, optional (default=0.)\n",
    "\n",
    "    리프에 있어야 하는 총 가중치 중 최소 가중치. sample_weight가 제공되지 않은 경우 샘플의 가중치는 동일합니다.\n",
    "\n",
    "\n",
    "max_leaf_nodes : int or None, optional (default=None)\n",
    "\n",
    "    max_leaf_nodes가 있는 나무를 최상의 방법으로 성장시킵니다. 최상의 노드는 불순물의 상대적 감소로 정의됩니다.\n",
    "    \n",
    "    None이면 리프의 개수에 제한이 없습니다.\n",
    "\n",
    "\n",
    "bootstrap : boolean, optional (default=True)\n",
    "\n",
    "    부트스트랩 샘플을 사용할지 여부\n",
    "    \n",
    "\n",
    "oob_score : bool (default=False)\n",
    "\n",
    "    Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
    "\n",
    "n_jobs : integer, optional (default=1)\n",
    "\n",
    "    병렬로 실행할 작업 수입니다. -1이면 작업 수는 코어 수로 설정됩니다.\n",
    "    \n",
    "\n",
    "random_state : int, RandomState instance or None, optional (default=None)\n",
    "\n",
    "    If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.\n",
    "\n",
    "verbose : int, optional (default=0)\n",
    "\n",
    "    Controls the verbosity of the tree building process.\n",
    "\n",
    "warm_start : bool, optional (default=False)\n",
    "\n",
    "    When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest.\n",
    "\n",
    "class_weight : dict, list of dicts, “balanced”,\n",
    "\n",
    "    “balanced_subsample” or None, optional (default=None) Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.\n",
    "\n",
    "    Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].\n",
    "\n",
    "    The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n",
    "\n",
    "    The “balanced_subsample” mode is the same as “balanced” except that weights are computed based on the bootstrap sample for every tree grown.\n",
    "\n",
    "    For multi-output, the weights of each column of y will be multiplied.\n",
    "\n",
    "    Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes\n",
    "\n",
    "estimators_ : list of DecisionTreeClassifier\n",
    "\n",
    "    The collection of fitted sub-estimators.\n",
    "\n",
    "classes_ : array of shape = [n_classes] or a list of such arrays\n",
    "\n",
    "    The classes labels (single output problem), or a list of arrays of class labels (multi-output problem).\n",
    "\n",
    "n_classes_ : int or list\n",
    "\n",
    "    The number of classes (single output problem), or a list containing the number of classes for each output (multi-output problem).\n",
    "\n",
    "n_features_ : int\n",
    "\n",
    "    The number of features when fit is performed.\n",
    "\n",
    "n_outputs_ : int\n",
    "\n",
    "    The number of outputs when fit is performed.\n",
    "\n",
    "feature_importances_ : array of shape = [n_features]\n",
    "\n",
    "    The feature importances (the higher, the more important the feature).\n",
    "\n",
    "oob_score_ : float\n",
    "\n",
    "    Score of the training dataset obtained using an out-of-bag estimate.\n",
    "\n",
    "oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
    "\n",
    "    Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, oob_decision_function_ might contain NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
