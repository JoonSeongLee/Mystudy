{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_list_train = pd.read_csv('../../team1_coupon/dev/data/coupon_list_train.csv')\n",
    "coupon_list_test = pd.read_csv('../../team1_coupon/dev/data/coupon_list_test.csv')\n",
    "user_list = pd.read_csv('../../team1_coupon/dev/data/user_list.csv')\n",
    "coupon_purchases_train = pd.read_csv(\"../../team1_coupon/dev/data/coupon_detail_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge to obtain (USER_ID) <-> (COUPON_ID with features) training set\n",
    "purchased_coupons_train = coupon_purchases_train.merge(coupon_list_train, on='COUPON_ID_hash', how='inner')\n",
    "purchased_coupons_train = purchased_coupons_train.merge(user_list, on = 'USER_ID_hash', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter redundant features\n",
    "features = ['COUPON_ID_hash', 'USER_ID_hash',\n",
    "            'GENRE_NAME', 'DISCOUNT_PRICE', 'PRICE_RATE',\n",
    "            'USABLE_DATE_MON', 'USABLE_DATE_TUE', 'USABLE_DATE_WED', 'USABLE_DATE_THU',\n",
    "            'USABLE_DATE_FRI', 'USABLE_DATE_SAT', 'USABLE_DATE_SUN', 'USABLE_DATE_HOLIDAY',\n",
    "            'USABLE_DATE_BEFORE_HOLIDAY', 'large_area_name', 'ken_name', 'small_area_name']\n",
    "purchased_coupons_train = purchased_coupons_train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create 'dummyuser' records in order to merge training and testing sets in one\n",
    "coupon_list_test['USER_ID_hash'] = 'dummyuser'\n",
    "### filter testing set consistently with training set\n",
    "coupon_list_test = coupon_list_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log10\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "### merge sets together\n",
    "combined = pd.concat([purchased_coupons_train, coupon_list_test], axis=0)\n",
    "### create two new features\n",
    "combined['DISCOUNT_PRICE'] = 1 / np.log10(combined['DISCOUNT_PRICE'])\n",
    "combined['PRICE_RATE'] = (combined['PRICE_RATE'] / 100) ** 2\n",
    "features.extend(['DISCOUNT_PRICE', 'PRICE_RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert categoricals to OneHotEncoder form\n",
    "categoricals = ['GENRE_NAME', 'USABLE_DATE_MON', 'USABLE_DATE_TUE', 'USABLE_DATE_WED',\n",
    "                'USABLE_DATE_THU', 'USABLE_DATE_FRI', 'USABLE_DATE_SAT', 'USABLE_DATE_SUN',\n",
    "                'USABLE_DATE_HOLIDAY', 'USABLE_DATE_BEFORE_HOLIDAY', 'large_area_name', 'ken_name', 'small_area_name']\n",
    "combined_categoricals = combined[categoricals]\n",
    "combined_categoricals = pd.get_dummies(combined_categoricals,\n",
    "                                    dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "### leaving continuous features as is, obtain transformed dataset\n",
    "continuous = list(set(features) - set(categoricals))\n",
    "combined = pd.concat([combined[continuous], combined_categoricals], axis=1)\n",
    "### remove NaN values\n",
    "NAN_SUBSTITUTION_VALUE = 1\n",
    "combined = combined.fillna(NAN_SUBSTITUTION_VALUE)\n",
    "### split back into training and testing sets\n",
    "train = combined[combined['USER_ID_hash'] != 'dummyuser']\n",
    "test = combined[combined['USER_ID_hash'] == 'dummyuser']\n",
    "test.drop('USER_ID_hash', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find most appropriate coupon for every user (mean of all purchased coupons), in other words, user profile\n",
    "train_dropped_coupons = train.drop('COUPON_ID_hash', axis=1)\n",
    "user_profiles = train_dropped_coupons.groupby(by='USER_ID_hash').mean()\n",
    "test_only_features = test.drop('COUPON_ID_hash', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "def cosine_similarity(vector_1, vector_2):\n",
    "    \n",
    "    idx = vector_1.nonzero()[0]\n",
    "    if len(idx) == 0:\n",
    "        return 0\n",
    "    vector_1, vector_2 = np.array(vector_1)[idx], np.array(vector_2)[idx]\n",
    "    \n",
    "    idx = vector_2.nonzero()[0]\n",
    "    if len(idx) == 0:\n",
    "        return 0\n",
    "    vector_1, vector_2 = np.array(vector_1)[idx], np.array(vector_2)[idx]\n",
    "    #print(vector_1, vector_2)\n",
    "    return 1 - spatial.distance.cosine(vector_1, vector_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40min 55s, sys: 11.5 s, total: 41min 6s\n",
      "Wall time: 41min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "matrix = []\n",
    "for idx1 in range(len(user_profiles)):\n",
    "    row = []\n",
    "    for idx2 in range(len(test_only_features)):\n",
    "        row.append(cosine_similarity(user_profiles.iloc[idx1], test_only_features.iloc[idx2]))\n",
    "    matrix.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupons_ids = test['COUPON_ID_hash']\n",
    "result_index = user_profiles.index\n",
    "result_columns = [coupons_ids[i] for i in range(0, test_only_features.T.shape[1])]\n",
    "result_df = pd.DataFrame(index= result_index, columns=result_columns,\n",
    "                      data=matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns=['USER_ID_hash','PURCHASED_COUPONS'])\n",
    "submission['USER_ID_hash'] = result_df.index\n",
    "submission['PURCHASED_COUPONS'] = result_df.T.apply(lambda x: \" \".join(x.sort_values(ascending=False)[:21].index)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "cur_time = now.strftime('%Y-%m-%d %H-%M-%S')\n",
    "\n",
    "submission.to_csv('cosine'+cur_time+'.csv',index = False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
