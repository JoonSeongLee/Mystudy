{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.neighbors.`KNeighborsClassifier`(n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=1, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters:\t\n",
    "\n",
    "n_neighbors : int, optional (default = 5)\n",
    "\n",
    "    Number of neighbors to use by default for kneighbors queries.\n",
    "    (근접 이웃 수 설명)\n",
    "\n",
    "weights : str or callable, optional (default = ‘uniform’)\n",
    "\n",
    "    weight function used in prediction. Possible values:\n",
    "    (예측에 사용된 가중치 함수)\n",
    "    \n",
    "    ‘uniform’  : uniform weights. All points in each neighborhood are weighted equally.\n",
    "                 (균일한 가중치, 각 이웃에있는 모든 점에 동일한 가중치가 적용)\n",
    "                 \n",
    "    ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a \n",
    "                 query point will have a greater influence than neighbors which are further away.\n",
    "                 (거리의 역수로 가중치, 이 경우 포인트의 인접한 이웃들이 멀리 떨어져있는 이웃들보다 더 큰 영향을 미침)\n",
    "                 \n",
    "algorithm  : {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, optional\n",
    "\n",
    "    Algorithm used to compute the nearest neighbors:\n",
    "    (가장 가까운 이웃을 계산하는 데 사용되는 알고리즘)\n",
    "    \n",
    "    ‘ball_tree’ will use BallTree\n",
    "    ‘kd_tree’ will use KDTree\n",
    "    ‘brute’ will use a brute-force search.\n",
    "    ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.\n",
    "    Note: fitting on sparse input will override the setting of this parameter, using brute force.\n",
    "\n",
    "leaf_size : int, optional (default = 30)\n",
    "\n",
    "    Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, \n",
    "    as well as the memory required to store the tree. The optimal value depends on the nature of the problem.\n",
    "    (BallTree 또는 KDTree에 전달 된 리프 크기)\n",
    "    \n",
    "p : integer, optional (default = 2)\n",
    "\n",
    "    Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1),\n",
    "    and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "\n",
    "metric : string or callable, default ‘minkowski’\n",
    "\n",
    "    the distance metric to use for the tree. The default metric is minkowski, and with p=2 is equivalent to \n",
    "    the standard Euclidean metric. See the documentation of the DistanceMetric class for a list of available metrics.\n",
    "\n",
    "metric_params : dict, optional (default = None)\n",
    "\n",
    "    Additional keyword arguments for the metric function.\n",
    "\n",
    "n_jobs : int, optional (default = 1)\n",
    "\n",
    "    The number of parallel jobs to run for neighbors search. If -1, then the number of jobs is set to \n",
    "    the number of CPU cores. Doesn’t affect fit method.\n",
    "    (인접 항목 검색을 위해 실행할 병렬 작업 수입니다. -1이면 작업 수는 CPU 코어 수로 설정됩니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Methods                                       |                                                               |\n",
    "|-----------------------------------------------|---------------------------------------------------------------|\n",
    "| fit(X, y)                                     | X를 학습 데이터로, y를 목표 값 |\n",
    "| get_params([deep])                            | Get parameters for this estimator.                            |\n",
    "| kneighbors([X, n_neighbors, return_distance]) | 한 지점의 K- 이웃을 찾습니다.                            |\n",
    "| kneighbors_graph([X, n_neighbors, mode])      | X의 점에 대한 k- 이웃의 (가중치가있는) 그래프를 계산합니다.  |\n",
    "| predict(X)                                    | 제공된 데이터의 클래스 레이블을 예측합니다.                |\n",
    "| predict_proba(X)                              | 테스트 데이터 X에 대한 확률 추정치.             |\n",
    "| score(X, y[, sample_weight])                  | 주어진 테스트 데이터 및 레이블의 평균 정확도를 반환합니다.  |\n",
    "| set_params(**params)                          | 이 estimator 매개 변수를 설정.                       |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
